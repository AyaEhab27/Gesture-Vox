![Gesture Vox Logo](https://postimg.cc/hzMyVpPB)
# Gesture Vox ✋🗣️  
ئ
**Gesture Vox** is a smart cross-platform application that bridges the communication gap between hearing individuals and those who use sign language. It offers **real-time sign-to-text/audio translation**, and **text/audio-to-sign** translation using a 3D animated character. The system also includes a built-in chat, OCR scanning, and a gesture-based keyboard to support users in diverse contexts.

---

## 🚀 Project Overview

Gesture Vox empowers users to:
- **Translate signs into text/audio** by using the phone’s camera.
- **Translate text/audio into sign language** via a 3D character.
- **Scan text from images** and convert it to signs.
- **Chat with other users** using regular text or sign-based inputs.
- **Share translations** as text, voice, or animated sign sequences.

---

## 🎯 Project Goals

- Build a real-time **gesture recognition system** for Arabic and English letters and numbers.
- Translate user-input text or voice to **animated sign language**.
- Provide a 3D avatar (Moushira) that performs signs to enhance accessibility and learning.
- Support **OCR** to recognize text from images and translate it into sign language.
- Enhance **social integration** through an inclusive chat system with custom sign language keyboard and GIFs.

---

## 🔍 Why We Chose This Approach

- Most real-life sign language expressions are for **entire words**, but due to **dataset limitations**, we adopted a **letter-by-letter translation** model. This allows flexibility and scalability in the early stage.
- Users can build full words and sentences manually, which improves model accuracy and reduces misinterpretation.
- Different **dialects** in Arabic make whole-word modeling very complex at this stage.
- Providing **language model selection** (Arabic/English) manually ensures better accuracy. It also allows tailored models for each language's gesture set.

---

## 👥 Target Users

- Deaf and hard-of-hearing individuals.
- Family, friends, or professionals who interact with them.
- Institutions like banks, hospitals, schools that seek to improve accessibility.
- Learners of sign language who want a practical and interactive experience.

---

## 📱 Key Features

| Feature                        | Description |
|-------------------------------|-------------|
| **Sign Translator**           | Real-time camera-based recognition of Arabic and English signs (letters/numbers) and instant text/audio generation. |
| **Word Translator**           | Converts input text or speech into sign language animations using a 3D avatar. |
| **Chat**                      | Text messaging between app users, with support for sign language inputs and animations. |
| **Sign Language Keyboard**    | Visual keyboard with hand sign images and GIFs for fast communication. |
| **OCR & Scan**                | Extracts text from images and translates it into sign animations. |
| **Sharing**                   | Share text, audio, or sign animation links across apps or through the in-app chat. |


---

## 🛠️ Technologies Used

- **Flutter** – Cross-platform UI
- **TensorFlow/Keras** – AI & Deep Learning models
- **MediaPipe** – Real-time hand tracking
- **Firebase** – Data storage and authentication
- **OpenCV** – OCR scanning
- **Text-to-Speech APIs** – For voice output
- **3D Animation Engine** – For sign visualization (Avatar: Moushira)


---

## 📬 Final Notes

Gesture Vox is a **step toward inclusive technology** that merges AI, accessibility, and creativity. It serves both as a **translator** and a **learning tool**, making everyday interactions more accessible for the deaf and hard-of-hearing community.

Let’s create a world where communication has no barriers! 🌍🤝





